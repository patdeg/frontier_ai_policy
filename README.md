# Frontier AI Policy ğŸ›¡ï¸ â€” *from PDF to Pull-Request*

> â€œCalifornia just turned a 53-page policy PDF into tomorrowâ€™s default compliance bar.  
>  This repo shows â€” in runnable code â€” how to clear that bar without losing sleep.â€  
>  â€” *Californiaâ€™s â€œTrust-but-Verifyâ€ Blueprint for Frontier AI*

---

## Whatâ€™s in here?

The Medium article dramatises five regulatory pillars â€” **Privacy, Fairness, Safety, Transparency, Reliability** â€” and each pillar becomes a bite-size Python example you can drop into CI.  
File names mirror the narrative (e.g. `1_A_age_scrub.py` = Chapter 1, Scene A).

> **Heads-up:** `codex.md` is a *machine-readable* index for automated agents.  
>  The table below is the *human-friendly* script catalogue.

| Pillar | Script range | One-liner |
|--------|--------------|-----------|
| Privacy | `1_A_*` â€“ `1_C_*` | Strip birthdays, kill creepy geo-guesses, bulk PII scans |
| Fairness | `2_A_*` â€“ `2_C_*` | Gender-swap gift tests, rÃ©sumÃ©-bias probes, million-row audits |
| Safety | `3_A_*` â€“ `3_D_*` | Illegal-request refusals, self-harm lifelines, 4 000-prompt red-team |
| Transparency | `4_A_*` â€“ `4_C_*` | One-sentence rationales, token heat-maps, trace-ID w/ SHA-256 |
| Reliability | `5_A_*` â€“ `5_C_*` | Math sanity checks, typo tornadoes, Chaos-Monkey load storms |

---

## Quick start

```bash
git clone https://github.com/patdeg/frontier_ai_policy.git
cd frontier_ai_policy

python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env        # add your API keys here

pytest                      # run all guardrail checks
````

---

## Which models?

We demo an **â€œunsafe baselineâ€ â†’ â€œsafe wrapperâ€** flow, so we need models with minimal built-in guardrails:

| Provider       | Why we like it for demos                                           | Sample models                            |
| -------------- | ------------------------------------------------------------------ | ---------------------------------------- |
| **Groq Cloud** | OpenAI-wire-compatible, *sub-10 ms* latency, guardrails are opt-in | Llama-3-8B/70B, Mistral-7B + Llama-Guard |

---

## ğŸš€ Groq Cloud â€” zero-to-token in 5 minutes

| Step | What to do                                                                                                                               |
| ---: | ---------------------------------------------------------------------------------------------------------------------------------------- |
|    1 | **Create an account:** [https://console.groq.com/](https://console.groq.com/) (GitHub, Google, or email).                                |
|    2 | **Generate an API key:** **API Keys â†’ Create API Key**, copy it once.                                                                    |
|    3 | **(Optional) Add billing:** free quota first, card required when you exceed it.                                                          |
|    4 | **Set env vars** in `.env`:<br>`GROQ_API_KEY=sk-â€¦`<br>`OPENAI_API_KEY=$GROQ_API_KEY`<br>`OPENAI_BASE_URL=https://api.groq.com/openai/v1` |
|    5 | **Ping the model:**                                                                                                                      |

```python
import os, openai

client = openai.OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL"),
)

resp = client.chat.completions.create(
    model="meta-llama/Meta-Llama-3-8B-Instruct",
    messages=[{"role": "user", "content": "Hi, I turned 30 today"}],
)

print(resp.choices[0].message.content)
# -> Happy 30th birthday! ğŸ‰
```

Swapping providers later is three lines of config.

---

## Project philosophy ğŸ¥‹

* **Tiny, test-first** â€” each script â‰¤ 100 LOC with an `assert` so CI fails loudly.
* **Show, donâ€™t tell** â€” runnable code beats policy prose.
* **Living checklist** â€” every PR must add or improve a guardrail; nothing lands un-tested.
* **Intentionally vulnerable** â€” the â€œunsafeâ€ path is left wide-open so newcomers feel the contrast.

---

## Contributing

1. Fork â†’ branch â†’ PR.
2. Keep examples small and self-contained.
3. **Update one line in `codex.md`** using the strict<br>`filename.py :: description :: TAGS` format (see its header).
4. Ensure `pytest` stays green.

---

## License

MIT. The â€œunsafeâ€ examples are for **educational use only** â€” donâ€™t ship them to production without the matching safety layer.

---

> *Trust, then verify  â€” and if itâ€™s an LLM, verify twice.*

